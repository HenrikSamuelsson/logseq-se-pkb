- Reading in the book [[Embedded Systems Architecture]], today on the topic of [[Real-time scheduling]].
- ## [[Real-time scheduling]]
  - *Real-time scheduling* is required when there is a need to react to events within a **short and predictable amount of time**.
  - These systems have timing constraints, including **deadlines**, which specify when a task must **start** or **complete** its execution.
  - One common strategy is static [[priority-driven preemptive scheduling]], where the most important tasks are assigned higher [[priority]], allowing them to **preempt** lower-priority tasks.
  - Another widely used approach is [[Earliest Deadline First]] (EDF), a **dynamic scheduling** method where the task with the **closest deadline** is selected to run next.
  - Blocking occurs when a task waits passively (without consuming CPU) for an external event or resource (e.g., I/O, semaphore, or message). Managing blocking behavior is critical in real-time systems to ensure tasks still meet their timing guarantees.
- ## [[Synchronization]]
  - A [[multithreaded]] evnironment with shared resources must include a mechanism to allow the task to work cooperatively with these tasks.
  - A realworld analogy would be a restaurant kitchen with multiple working chefs they would need to:
    - Share appliances like the oven, stove, or blender (shared peripherals or variables).
    - Take turns using them, or they might interfere with each other — like putting an ingredient in the blender when someone else is already using it (data corruption or race condition).
    - So, the kitchen has rules:
      - A sign-up sheet or timer slot for the oven (mutex/semaphore).
      - A verbal agreement like “Tell me when you’re done with the mixer” (event signaling).
      - Chefs clean up and step aside when not using a station (yielding CPU or releasing lock).
    - Without such mechanisms, chaos happens — food gets ruined (bugs), chefs bump into each other (deadlocks), and the kitchen becomes inefficient (resource contention).
- ## [[Semaphore]]
  - A *semaphore* is a [[synchronization]] tool used in multithreaded or multitasking environments to control access to shared resources.
  - There are two main types:
    * **Binary semaphore**: Acts like a lock (values 0 or 1); used to allow one task at a time into a critical section.
    * **Counting semaphore**: Allows a set number of tasks to access a resource, useful for managing pools (e.g., 3 identical devices).
  - Semaphores help prevent race conditions and ensure that tasks don't interfere with each other when using shared resources. Tasks may wait (block) if the semaphore isn't available, and resume when it is released.
  - ## [[Mutex]]
    - A *mutex* (short for mutual exclusion) is a synchronization primitive used to ensure that only one task accesses a shared resource at a time.
    - A mutex is similar to a binary semaphore, but there are key differences:
      - A mutex has ownership — only the task that locked (acquired) the mutex can unlock (release) it.
      - A binary semaphore, by contrast, does not enforce ownership — any task can signal (release) it.
      - A mutex is typically initialized with a value of 1, meaning it's unlocked and available to be taken by a task.
    - In short: All mutexes are binary semaphores, but not all binary semaphores are mutexes.
  - ## [[Priority inversion]]
    - Priority inversion can occur in environments with three or more tasks of different priorities when a low-priority task holds a resource (like a [[mutex]]) that a high-priority task needs, and the high-priority task ends up waiting for the low-priority one — even though it's supposed to have higher scheduling precedence.
    - Example of a chain of events that can cause priority inversion:
      1. A low-priority task locks a mutex.
      2. Before it can release it, a high-priority task tries to acquire the same mutex and [[blocks]], waiting for it.
      3. A medium-priority task (that doesn't need the mutex) runs and preempts the low-priority task — preventing it from releasing the mutex.
      4. Now, the high-priority task is effectively blocked by the medium-priority one — inverting the intended priority order.
    - Priority inversion is prevented by introducing [[priority inheritance]], which temporarily raises the priority of the low-priority task to match that of the high-priority task. This prevents the medium-priority task from causing latency.
